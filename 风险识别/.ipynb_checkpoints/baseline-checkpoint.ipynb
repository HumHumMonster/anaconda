{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "072e5af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from gensim.models import Word2Vec\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss, mean_squared_log_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import argparse\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4e7d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_info = pd.read_csv('./data/账户交易信息.csv')\n",
    "static_info = pd.read_csv('./data/账户静态信息.csv')\n",
    "\n",
    "train_label = pd.read_csv('./data/训练集标签.csv')\n",
    "test_label = pd.read_csv('./data/test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e8bc454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jyrq_month', 'jyrq_day', 'jyrq_weekofyear', 'jyrq_dayofyear', 'jyrq_dayofweek', 'jyrq_is_wknd', 'jyrq_is_month_start', 'jyrq_is_month_end', 'jyrq_hour', 'jyrq_minu', 'jyrq_date']\n",
      "(1200, 2) (4800, 1)\n"
     ]
    }
   ],
   "source": [
    "def get_time_feature(df, col):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    prefix = col + \"_\"\n",
    "    df_copy['new_'+col] = df_copy[col].astype(str)\n",
    "    \n",
    "    col = 'new_'+col\n",
    "    df_copy[col] = pd.to_datetime(df_copy[col], format='%Y-%m-%d')\n",
    "    df_copy[prefix + 'month'] = df_copy[col].dt.month\n",
    "    df_copy[prefix + 'day'] = df_copy[col].dt.day\n",
    "    df_copy[prefix + 'weekofyear'] = df_copy[col].dt.weekofyear\n",
    "    df_copy[prefix + 'dayofyear'] = df_copy[col].dt.dayofyear\n",
    "    df_copy[prefix + 'dayofweek'] = df_copy[col].dt.dayofweek\n",
    "    df_copy[prefix + 'is_wknd'] = df_copy[col].dt.dayofweek // 6\n",
    "    df_copy[prefix + 'is_month_start'] = df_copy[col].dt.is_month_start.astype(int)\n",
    "    df_copy[prefix + 'is_month_end'] = df_copy[col].dt.is_month_end.astype(int)\n",
    "    del df_copy[col]\n",
    "    \n",
    "    df_copy[prefix + 'hour'] = df_copy['jysj'].apply(lambda x:int(x.split(':')[0]))\n",
    "    df_copy[prefix + 'minu'] = df_copy['jysj'].apply(lambda x:int(x.split(':')[1]))\n",
    "    df_copy[prefix + 'date'] = df_copy['jysj'].apply(lambda x:int(x.split(':')[0])*60 + int(x.split(':')[1]))\n",
    "    \n",
    "    return df_copy   \n",
    "\n",
    "trans_info = get_time_feature(trans_info, \"jyrq\")\n",
    "time_cols = [f for f in trans_info.columns if 'jyrq_' in f]\n",
    "print(time_cols)\n",
    "print(train_label.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0b5a5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_base_feat(df1_, df2_):\n",
    "    df1 = df1_.copy() # 构建特征数据 \n",
    "    df2 = df2_.copy()\n",
    "\n",
    "    agg_func = {\n",
    "        'dfzh': ['nunique','count'],\n",
    "        'dfhh': ['nunique'],\n",
    "        'jyqd': ['nunique'],\n",
    "        'zydh': ['nunique'],\n",
    "        'jyje': ['sum','mean','max','min','std',np.ptp],\n",
    "        'zhye': ['sum','mean','max','min','std',np.ptp],\n",
    "        'dfmccd': ['mean','max','min','std',np.ptp],\n",
    "    }\n",
    "    \n",
    "    for col in time_cols:\n",
    "        agg_func[col] = ['mean','min','max',np.ptp]\n",
    "    \n",
    "    agg_df = df1[df1['jdbj']==0].groupby(['zhdh']).agg(agg_func).reset_index()\n",
    "    agg_df.columns = ['zhdh'] + ['zhdh_jdbj0_' + '_'.join(f).strip() for f in agg_df.columns.values if f[0] not in ['zhdh']]\n",
    "    df2 = df2.merge(agg_df, on=['zhdh'], how='left')\n",
    "    \n",
    "    agg_df = df1[df1['jdbj']==1].groupby(['zhdh']).agg(agg_func).reset_index()\n",
    "    agg_df.columns = ['zhdh'] + ['zhdh_jdbj1_' + '_'.join(f).strip() for f in agg_df.columns.values if f[0] not in ['zhdh']]\n",
    "    df2 = df2.merge(agg_df, on=['zhdh'], how='left')\n",
    "    \n",
    "    return df2\n",
    "\n",
    "train_label = get_base_feat(trans_info, train_label)\n",
    "test_label = get_base_feat(trans_info, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9584b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 合并账户静态信息\n",
    "static_info['khrq']  = pd.to_datetime(static_info['khrq'], format='%Y-%m-%d')\n",
    "static_info['year']  = static_info['khrq'].dt.year\n",
    "static_info['month'] = static_info['khrq'].dt.month\n",
    "static_info['day']   = static_info['khrq'].dt.day\n",
    "\n",
    "# 自然数编码\n",
    "def label_encode(series):\n",
    "    unique = list(series.unique())\n",
    "    return series.map(dict(zip(\n",
    "        unique, range(series.nunique())\n",
    "    )))\n",
    "\n",
    "for col in ['khjgdh']:\n",
    "    static_info[col] = label_encode(static_info[col])\n",
    "\n",
    "keep_cols = ['zhdh','year','month','day','khjgdh','xb','年龄']\n",
    "\n",
    "train_label = train_label.merge(static_info[keep_cols], on=['zhdh'], how='left')\n",
    "test_label  = test_label.merge(static_info[keep_cols], on=['zhdh'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b78424c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [f for f in train_label.columns if f not in ['zhdh','black_flag']]\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "999a572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model(clf, train_x, train_y, test_x, clf_name):\n",
    "    folds = 5\n",
    "    seed = 2023\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "    \n",
    "    oof = np.zeros(train_x.shape[0])\n",
    "    predict = np.zeros(test_x.shape[0])\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} ************************************'.format(str(i+1)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "\n",
    "        if clf_name == \"lgb\":\n",
    "            train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "            valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "\n",
    "            params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': 'auc',\n",
    "                'min_child_weight': 5,\n",
    "                'num_leaves': 2 ** 5,\n",
    "                'lambda_l2': 10,\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 0.8,\n",
    "                'bagging_freq': 4,\n",
    "                'learning_rate': 0.01,\n",
    "                'seed': 2020,\n",
    "                'n_jobs':8\n",
    "            }\n",
    "\n",
    "            model = clf.train(params, train_matrix, 10000, valid_sets=[train_matrix, valid_matrix], \n",
    "                              categorical_feature=[], verbose_eval=200, early_stopping_rounds=200)\n",
    "            val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "            test_pred = model.predict(test_x, num_iteration=model.best_iteration)\n",
    "            \n",
    "            print(list(sorted(zip(features, model.feature_importance(\"gain\")), key=lambda x: x[1], reverse=True))[:20])\n",
    "                \n",
    "        if clf_name == \"xgb\":\n",
    "            train_matrix = clf.DMatrix(trn_x , label=trn_y)\n",
    "            valid_matrix = clf.DMatrix(val_x , label=val_y)\n",
    "            test_matrix = clf.DMatrix(test_x)\n",
    "            \n",
    "            params = {'booster': 'gbtree',\n",
    "                      'objective': 'binary:logistic',\n",
    "                      'eval_metric': 'auc',\n",
    "                      'gamma': 1,\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'max_depth': 5,\n",
    "                      'lambda': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'eta': 0.05,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 2020,\n",
    "                      'nthread': 8\n",
    "                      }\n",
    "            \n",
    "            watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]\n",
    "            \n",
    "            model = clf.train(params, train_matrix, num_boost_round=10000, evals=watchlist, verbose_eval=1000, early_stopping_rounds=500)\n",
    "            val_pred  = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit)\n",
    "            test_pred = model.predict(test_matrix , ntree_limit=model.best_ntree_limit)\n",
    "                 \n",
    "        if clf_name == \"cat\":\n",
    "            \n",
    "            model = clf(\n",
    "                        n_estimators=10000,\n",
    "                        random_seed=1024,\n",
    "                        eval_metric='AUC',\n",
    "                        learning_rate=0.05,\n",
    "                        max_depth=5,\n",
    "                        early_stopping_rounds=200,\n",
    "                        metric_period=500,\n",
    "                    )\n",
    "\n",
    "            model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                      use_best_model=True,\n",
    "                      verbose=1)\n",
    "            \n",
    "            val_pred  = model.predict_proba(val_x)[:,1]\n",
    "            test_pred = model.predict_proba(test_x)[:,1]\n",
    "            \n",
    "        oof[valid_index] = val_pred\n",
    "        predict += test_pred / kf.n_splits\n",
    "        \n",
    "        cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "        print(cv_scores)\n",
    "       \n",
    "    return oof, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df339a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "[0]\ttrain-auc:0.87682\teval-auc:0.86880\n",
      "[532]\ttrain-auc:0.99962\teval-auc:0.95898\n",
      "[0.9649074074074074]\n",
      "************************************ 2 ************************************\n",
      "[0]\ttrain-auc:0.91329\teval-auc:0.87092\n",
      "[709]\ttrain-auc:0.99966\teval-auc:0.95632\n",
      "[0.9649074074074074, 0.9591337441101848]\n",
      "************************************ 3 ************************************\n",
      "[0]\ttrain-auc:0.91741\teval-auc:0.84973\n",
      "[793]\ttrain-auc:0.99981\teval-auc:0.94870\n",
      "[0.9649074074074074, 0.9591337441101848, 0.9510565110565111]\n",
      "************************************ 4 ************************************\n",
      "[0]\ttrain-auc:0.91198\teval-auc:0.90292\n",
      "[610]\ttrain-auc:0.99966\teval-auc:0.96458\n",
      "[0.9649074074074074, 0.9591337441101848, 0.9510565110565111, 0.9724688368756165]\n",
      "************************************ 5 ************************************\n",
      "[0]\ttrain-auc:0.90593\teval-auc:0.86213\n",
      "[572]\ttrain-auc:0.99970\teval-auc:0.94472\n",
      "[0.9649074074074074, 0.9591337441101848, 0.9510565110565111, 0.9724688368756165, 0.951574074074074]\n"
     ]
    }
   ],
   "source": [
    "xgb_oof, xgb_pred = cv_model(xgb, train_label[cols], train_label['black_flag'], test_label[cols], 'xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "705b8e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40, 0.9012148491870569\n",
      "0.41, 0.9030299342790133\n",
      "0.42, 0.9046304958352445\n",
      "0.43, 0.9054369887446954\n",
      "0.44, 0.904167280053805\n",
      "0.45, 0.9052063303674989\n",
      "0.46, 0.9011320381630332\n",
      "0.47, 0.8998447204968945\n",
      "0.48, 0.902976082045607\n",
      "0.49, 0.902976082045607\n",
      "0.50, 0.9037825956013783\n",
      "0.51, 0.904835660388627\n",
      "0.52, 0.9056511056511056\n",
      "0.53, 0.9043494433668996\n",
      "0.54, 0.9041033316199533\n",
      "0.55, 0.8988447475135146\n",
      "0.56, 0.8961936684103612\n",
      "0.57, 0.8961936684103612\n",
      "0.58, 0.8959204609008862\n",
      "0.59, 0.8969809015369012\n",
      "0.52, 0.9056511056511056\n"
     ]
    }
   ],
   "source": [
    "oof = xgb_oof\n",
    "scores = []; thresholds = []\n",
    "best_score = 0; best_threshold = 0\n",
    "\n",
    "for threshold in np.arange(0.4,0.6,0.01):\n",
    "    preds = (oof.reshape((-1))>threshold).astype('int')\n",
    "    m = f1_score(train_label['black_flag'].values.reshape((-1)), preds, average='macro')   \n",
    "    scores.append(m)\n",
    "    thresholds.append(threshold)\n",
    "    if m>best_score:\n",
    "        best_score = m\n",
    "        best_threshold = threshold\n",
    "    print(f'{threshold:.02f}, {m}')\n",
    "print(f'{best_threshold:.02f}, {best_score}')\n",
    "# 0.47, 0.9150898680694286 # 0.86579572447\n",
    "# 0.43, 0.9217716422203048 # 0.86697783\n",
    "# 0.41, 0.9198568108353592 # 0.87674418605\n",
    "# 0.40, 0.9231997065541027 # 0.87819025522\n",
    "# 0.42, 0.913822737200522  # 0.87639132982 \n",
    "# 0.40, 0.9148403872302214 # 0.88313184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4032d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgb_pred\n",
    "test_label['black_flag'] = (pred.reshape((-1))>best_threshold).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee47bdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label[['zhdh','black_flag']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32107a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21104166666666666, 0.25)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label['black_flag'].mean(), train_label['black_flag'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e221dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
