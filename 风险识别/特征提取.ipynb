{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from gensim.models import Word2Vec\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss, mean_squared_log_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import argparse\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping\n",
    "from lightgbm import log_evaluation\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import category_encoders as ce\n",
    "import pickle\n",
    "#计算shap值\n",
    "import shap\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)  # 显示所有行\n",
    "pd.set_option('display.max_columns', None)  # 显示所有列\n",
    "pd.set_option('expand_frame_repr', False)  # 即“禁止换行”\n",
    "# pd.set_option('display.precision', 2) #展示两位小数点\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_交易=pd.read_csv('data/账户交易信息.csv')\n",
    "df_data_交易.columns = ['交易流水序号','账户代号','对方账号','借贷标志','交易金额','交易余额','对方行号','交易日期','交易时间','交易渠道','摘要代号','对方名称长度']\n",
    "df_data_账户=pd.read_csv('data/账户静态信息.csv')\n",
    "df_data_账户.columns = ['账户代号','开户日期','开户行代号','客户性别','年龄']\n",
    "df_label_train=pd.read_csv('data/训练集标签.csv')\n",
    "df_label_train.columns = ['账户代号','label']\n",
    "df_label_test=pd.read_csv('data/test_dataset.csv')\n",
    "df_label_test.columns = ['账户代号']## 读取数据\n",
    "df_label_all=pd.concat([df_label_train,df_label_test])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 抹账处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tz = df_label_all.copy() ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_交易_金额为负_index = list(df_data_交易[df_data_交易[\"交易金额\"] < 0].index)\n",
    "list_mz_index = [] ;\n",
    "list_交易_金额为负_对应的失败交易_index = [] ;\n",
    "for i in list_交易_金额为负_index :\n",
    "    S_now = df_data_交易.loc[i] ;\n",
    "    j = i ;\n",
    "    while (True) :\n",
    "        j -= 1 ;\n",
    "        S_nex = df_data_交易.loc[j] ;\n",
    "        if (S_now[\"交易金额\"] == -S_nex[\"交易金额\"]) :\n",
    "            if (S_now[\"账户代号\"] == S_nex[\"账户代号\"]) :\n",
    "                list_交易_金额为负_对应的失败交易_index.append(j) ;\n",
    "                list_mz_index.append(i) ;\n",
    "                break ;\n",
    "list_交易_抹账需要去除_index = list_交易_金额为负_index + list_交易_金额为负_对应的失败交易_index ;\n",
    "df_data_交易_去除抹账后=df_data_交易[~df_data_交易.index.isin(list_交易_抹账需要去除_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出抹账的数据\n",
    "df_data_抹账_账户代号与交易金额 = df_data_交易.loc[list_交易_金额为负_对应的失败交易_index , ['账户代号' , '交易金额']] ;\n",
    "df_tz_抹账 = df_data_抹账_账户代号与交易金额.groupby('账户代号')['交易金额'].agg(['sum','count','mean','max','min','std',np.ptp]).reset_index() ;\n",
    "df_tz_抹账.columns = ['账户代号'] + ['抹账_'+ f for f in df_tz_抹账.columns.values if f not in ['账户代号']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tz=df_tz.merge(df_tz_抹账,on='账户代号',how='left') ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 交易渠道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取客户的交易总数\n",
    "df_tz_交易总数 = df_data_交易_去除抹账后.groupby(\"账户代号\")[[\"账户代号\"]].agg([\"count\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_tz_交易总数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('账户代号', 'count')],\n",
       "           )"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tz_交易总数.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The column label '账户代号' is not unique.\nFor a multi-index, the label must be a tuple with elements corresponding to each level.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28716\\1160440866.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_tz_交易总数\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"账户代号\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36msort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   6320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6321\u001b[0m             \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6322\u001b[1;33m             \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6324\u001b[0m             \u001b[1;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m             \u001b[0mlabel_axis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"column\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"index\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1855\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   1856\u001b[0m                 \u001b[1;34mf\"The {label_axis_name} label '{key}' is not unique.{multi_message}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: The column label '账户代号' is not unique.\nFor a multi-index, the label must be a tuple with elements corresponding to each level."
     ]
    }
   ],
   "source": [
    "df_tz_交易总数.sort_values(\"账户代号\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 每个客户针对每个交易渠道，去取有多少;\n",
    "for i in df_data_交易_去除抹账后[\"交易渠道\"].unique() :\n",
    "    df_now = df_data_交易_去除抹账后[(df_data_交易_去除抹账后[\"交易渠道\"] == i)].groupby(\"账户代号\")[\"交易金额\",\"交易余额\"].agg([\"count\",'sum','mean','max','min','std']).reset_index() ;\n",
    "    df_now.columns = [\"账户代号\"] + [\"渠道代号_\" + i + \"_\" + \"_\".join(f) for f in df_now.columns if f[0] != \"账户代号\"]\n",
    "    df_mid = df_mid.merge(df_now , how=\"left\") ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mid.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征筛选、训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = df_all[:len(df_label_train)] ;\n",
    "test_label = df_all[len(df_label_train):] ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_filter(train_data,corr_threshold):\n",
    "    corr_data=train_data.corr()\n",
    "    corr_data=corr_data.where(np.triu(np.ones(corr_data.shape),k=1).astype(np.bool))\n",
    "    high_corr=[column for column in corr_data.columns if any(corr_data[column].abs()>corr_threshold)]\n",
    "    result=[c for c in train_data.columns if c not in high_corr]\n",
    "    print(\"筛选后特征:\",len(result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [f for f in train_label.columns if f not in ['账户代号','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols =corr_filter(train_label[cols],0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 对抗验证获取数据(df_train,df_test,threshold):\n",
    "    # 定义新的Y\n",
    "    \n",
    "    \n",
    "    df_train['Is_Test'] = 0\n",
    "    df_test['Is_Test'] = 1\n",
    "    #print(df_train.columns)\n",
    "    #print(df_test.columns)\n",
    "    # 将 Train 和 Test 合成一个数据集。\n",
    "    df_adv = pd.concat([df_train, df_test])\n",
    "    #print(df_adv.columns)\n",
    "    #catecol_list_index=[list(df_train.columns).index(c) for c in df_train.select_dtypes(include=['category']).columns]\n",
    "    # 通过抗验证中的模型，得到各个样本属于测试集的概率\n",
    "\n",
    "\n",
    "    \n",
    "    model_adv =  lgb.LGBMClassifier()\n",
    "    model_adv.fit(df_adv.drop(['label','Is_Test'], axis=1), df_adv.loc[:, 'Is_Test'])\n",
    "    preds_adv = model_adv.predict_proba(df_adv.drop(['label','Is_Test'], axis=1))[:, 1]\n",
    "    \n",
    "    df_train_copy = df_train.copy()\n",
    "    df_train_copy['is_test_prob'] = preds_adv[:len(df_train)]\n",
    "\n",
    "    # 根据概率排序\n",
    "    df_train_copy = df_train_copy.sort_values('is_test_prob').reset_index(drop=True)\n",
    "\n",
    "    # 将概率最大的20%作为验证集\n",
    "    df_validation_2 = df_train_copy.iloc[int(threshold * len(df_train)):, ]\n",
    "    df_train_2 = df_train_copy.iloc[:int(threshold * len(df_train)), ]\n",
    "    return df_validation_2.drop(['is_test_prob','Is_Test'], axis=1)#,df_train_copy.drop(['Is_Test'],axis=1)\n",
    "def 对抗验证获得新的列(df_train,df_test,threshold):\n",
    "    # 定义新的Y\n",
    "    df_train['Is_Test'] = 0\n",
    "    df_test['Is_Test'] = 1\n",
    "\n",
    "    # 将 Train 和 Test 合成一个数据集。\n",
    "    df_adv = pd.concat([df_train, df_test])\n",
    "\n",
    "    # 通过抗验证中的模型，得到各个样本属于测试集的概率\n",
    "    other_param={'boosting_type':'gbdt','num_leaves':32,'max_depth':10,'n_estimators':200,'objective':'binary','subsample':0.7,'colsample_bytree':0.8,'subsample_freq':1,\n",
    "               'min_child_weight':0.9,'learning_rate':0.08}\n",
    "    model_adv =  lgb.LGBMClassifier(**other_param)\n",
    "    model_adv.fit(df_adv.drop('Is_Test', axis=1), df_adv.loc[:, 'Is_Test'])\n",
    "    #preds_adv = model_adv.predict_proba(df_adv.drop('Is_Test', axis=1))[:, 1]\n",
    "    \n",
    "    im=pd.DataFrame({'colname':df_train.drop(['Is_Test'],axis=1).columns,'importance':model_adv.feature_importances_})\n",
    "\n",
    "    im=im.sort_values(by='importance',ascending=False)\n",
    "        \n",
    "    new_cat=im.reset_index().loc[round(len(im)*threshold):,'colname']\n",
    "    print('对抗验证后的特征数量为:',len(new_cat))\n",
    "    return new_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat=对抗验证获得新的列(train_label[cols].copy(),test_label[cols].copy(),0.6)\n",
    "cols=list(new_cat)\n",
    "col_valid=cols.copy()\n",
    "col_valid.append('label')\n",
    "valid=对抗验证获取数据(train_label[col_valid].copy(),test_label[cols].copy(),0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_cat=对抗验证获得新的列(train_label[cols].copy(),test_label[cols].copy(),0)\n",
    "# cols=list(new_cat)\n",
    "# col_valid=cols.copy()\n",
    "# col_valid.append('label')\n",
    "# valid=对抗验证获取数据(train_label[col_valid].copy(),test_label[cols].copy(),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model(clf, train_x, train_y, test_x, clf_name,valid_x):\n",
    "    folds = 5\n",
    "    seed = 2023\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "    \n",
    "    oof = np.zeros(train_x.shape[0])\n",
    "    predict = np.zeros(test_x.shape[0])\n",
    "    predict_valid = np.zeros(valid_x.shape[0])\n",
    "    cv_scores = []\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} ************************************'.format(str(i+1)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "\n",
    "        if clf_name == \"lgb\":\n",
    "            train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "            valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "\n",
    "            params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': 'auc',\n",
    "                'min_child_weight': 5,\n",
    "                'num_leaves': 2 ** 5,\n",
    "                'lambda_l2': 10,\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 0.8,\n",
    "                'bagging_freq': 4,\n",
    "                'learning_rate': 0.01,\n",
    "                'seed': 2020,\n",
    "                'n_jobs':8\n",
    "            }\n",
    "\n",
    "            model = clf.train(params, train_matrix, 10000, valid_sets=[train_matrix, valid_matrix], \n",
    "                              categorical_feature=[], verbose_eval=200, early_stopping_rounds=200)\n",
    "            val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "            test_pred = model.predict(test_x, num_iteration=model.best_iteration)\n",
    "            \n",
    "            print(list(sorted(zip(features, model.feature_importance(\"gain\")), key=lambda x: x[1], reverse=True))[:20])\n",
    "                \n",
    "        if clf_name == \"xgb\":\n",
    "            train_matrix = clf.DMatrix(trn_x , label=trn_y)\n",
    "            valid_matrix = clf.DMatrix(val_x , label=val_y)\n",
    "            test_matrix = clf.DMatrix(test_x)\n",
    "            \n",
    "            params = {'booster': 'gbtree',\n",
    "                      'objective': 'binary:logistic',\n",
    "                      'eval_metric': 'auc',\n",
    "                      'gamma': 1,\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'max_depth': 5,\n",
    "                      'lambda': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'eta': 0.05,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 2020,\n",
    "                      'nthread': 8\n",
    "                      }\n",
    "            \n",
    "            watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]\n",
    "            \n",
    "            model = clf.train(params, train_matrix, num_boost_round=10000, evals=watchlist, verbose_eval=1000, early_stopping_rounds=500)\n",
    "            val_pred  = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit)\n",
    "            test_pred = model.predict(test_matrix , ntree_limit=model.best_ntree_limit)\n",
    "            \n",
    "            valid_dk_matrix = clf.DMatrix(valid_x)\n",
    "            valid_pred= model.predict(valid_dk_matrix, ntree_limit=model.best_ntree_limit)\n",
    "        if clf_name == \"cat\":\n",
    "            model = clf(\n",
    "                        n_estimators=10000,\n",
    "                        random_seed=2023,\n",
    "                        eval_metric='AUC',\n",
    "                        learning_rate=0.05,\n",
    "                        max_depth=7,\n",
    "                        early_stopping_rounds=200,\n",
    "                        metric_period=500,\n",
    "                    )\n",
    "\n",
    "            model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                      use_best_model=True,\n",
    "                      verbose=1)\n",
    "            \n",
    "            val_pred  = model.predict_proba(val_x)[:,1]\n",
    "            test_pred = model.predict_proba(test_x)[:,1]\n",
    "            valid_pred= model.predict_proba(valid_x)[:,1]\n",
    "            \n",
    "        oof[valid_index] = val_pred\n",
    "        predict += test_pred / kf.n_splits\n",
    "        predict_valid +=valid_pred / kf.n_splits\n",
    "        cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "        print(cv_scores)\n",
    "       \n",
    "    return oof, predict,predict_valid,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_oof, xgb_pred,xgb_valid_pred,clf = cv_model(CatBoostClassifier, train_label[cols], train_label['label'], test_label[cols], 'cat',valid[cols])\n",
    "#xgb_oof, xgb_pred,xgb_valid_pred,clf = cv_model(xgb, train_label[cols], train_label['label'], test_label[cols], 'xgb',valid[cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(clf)\n",
    "\n",
    "shap_values = explainer.shap_values(train_label[cols])\n",
    "#shap.summary_plot(shap_values[1], train_label[cols])\n",
    "shap.summary_plot(shap_values, train_label[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgb_pred\n",
    "test_label['label'] = (pred.reshape((-1))>0.42).astype('int')\n",
    "result=test_label[['账户代号','label']]\n",
    "result.columns=['zhdh','black_flag']\n",
    "result.to_csv('submission20230305.csv', index=False)\n",
    "result['black_flag'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
